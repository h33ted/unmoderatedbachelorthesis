{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Tool to evaluate the results of the toxicity classifier for analysis \n",
    "\n",
    "George Cotea, 2024 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7705c851b5b49fed"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-13T13:38:59.386875Z",
     "start_time": "2024-05-13T13:38:59.120811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of messages:  31509\n",
      "Percentage of toxic messages:  1.1901361515757403\n",
      "Percentage of non-toxic messages:  98.80986384842426\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Unnamed: 0     id                      message classification     score\n36           36  77276                  Thanks dear      not_toxic  0.489006\n50           50  77261                       Great!      not_toxic  0.120459\n87           87  77219                     Hey guys      not_toxic  0.276745\n138         138  77161                        Hahha      not_toxic  0.273004\n149         149  77150  Hmmm Yoo dude must be crazy      not_toxic  0.198796",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>message</th>\n      <th>classification</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>77276</td>\n      <td>Thanks dear</td>\n      <td>not_toxic</td>\n      <td>0.489006</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>50</td>\n      <td>77261</td>\n      <td>Great!</td>\n      <td>not_toxic</td>\n      <td>0.120459</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>87</td>\n      <td>77219</td>\n      <td>Hey guys</td>\n      <td>not_toxic</td>\n      <td>0.276745</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>138</td>\n      <td>77161</td>\n      <td>Hahha</td>\n      <td>not_toxic</td>\n      <td>0.273004</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>149</td>\n      <td>77150</td>\n      <td>Hmmm Yoo dude must be crazy</td>\n      <td>not_toxic</td>\n      <td>0.198796</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import prettyprinter as pp \n",
    "\n",
    "# Import the dataset (in this case, Basic Moderation, Group A)\n",
    "df = pd.read_csv('/Users/george/Desktop/Uni/2023-2024/Thesis/Final Thesis Collection/distilClassified/nomoderation2toxicity.csv')\n",
    "\n",
    "# Output total number of rows (messages) \n",
    "print(\"Total number of messages: \", len(df))\n",
    "# Output the percentage of messages that contain 'toxic' in the classification column\n",
    "print(\"Percentage of toxic messages: \", len(df[df['classification'] == 'toxic']) / len(df) * 100)\n",
    "# Output the percentage of messages that contain 'non-toxic' in the classification column\n",
    "print(\"Percentage of non-toxic messages: \", len(df[df['classification'] == 'not_toxic']) / len(df) * 100)\n",
    "# Calculate the 95th percentile for the scores of toxic and non-toxic messages\n",
    "toxic_threshold = df[df['classification'] == 'toxic']['score'].quantile(0.95)\n",
    "non_toxic_threshold = df[df['classification'] == 'not_toxic']['score'].quantile(0.95)\n",
    "\n",
    "# Filter out the outliers\n",
    "toxic_outliers = df[(df['classification'] == 'toxic') & (df['score'] > toxic_threshold)]\n",
    "non_toxic_outliers = df[(df['classification'] == 'not_toxic') & (df['score'] > non_toxic_threshold)]\n",
    "\n",
    "# Print the toxic outliers df \n",
    "non_toxic_outliers.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0     id                            message classification  \\\n957          957  76267  Yah sometimes keyboard act stupid          toxic   \n2052        2052  74540           Let fucking do this guys          toxic   \n2789        2789  73615  What fuck do you mean do you mean          toxic   \n3690        3690  72587                      That what sup          toxic   \n3860        3860  72400           You be suprise and shock          toxic   \n\n         score  \n957   0.995131  \n2052  0.996683  \n2789  0.995723  \n3690  0.992770  \n3860  0.989853  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>message</th>\n      <th>classification</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>957</th>\n      <td>957</td>\n      <td>76267</td>\n      <td>Yah sometimes keyboard act stupid</td>\n      <td>toxic</td>\n      <td>0.995131</td>\n    </tr>\n    <tr>\n      <th>2052</th>\n      <td>2052</td>\n      <td>74540</td>\n      <td>Let fucking do this guys</td>\n      <td>toxic</td>\n      <td>0.996683</td>\n    </tr>\n    <tr>\n      <th>2789</th>\n      <td>2789</td>\n      <td>73615</td>\n      <td>What fuck do you mean do you mean</td>\n      <td>toxic</td>\n      <td>0.995723</td>\n    </tr>\n    <tr>\n      <th>3690</th>\n      <td>3690</td>\n      <td>72587</td>\n      <td>That what sup</td>\n      <td>toxic</td>\n      <td>0.992770</td>\n    </tr>\n    <tr>\n      <th>3860</th>\n      <td>3860</td>\n      <td>72400</td>\n      <td>You be suprise and shock</td>\n      <td>toxic</td>\n      <td>0.989853</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_outliers.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T13:39:03.262477Z",
     "start_time": "2024-05-13T13:39:03.257643Z"
    }
   },
   "id": "70575152685eb696"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0      id                                            message  \\\n0              0  957048  So considering battery degradation age and cycles   \n1              1  957047         so yeah it had its fair life at this point   \n2              2  957046  it’s an Oct 2020 unit, used since Dec 2020 by ...   \n3              3  957045  I do hope it goes service instantly cause aasp...   \n4              4  957044  When you actually put that into perspective yo...   \n...          ...     ...                                                ...   \n2995        2995  953725                         need to get ready for work   \n2996        2996  953724                                                 gm   \n2997        2997  953723                                      i can confirm   \n2998        2998  953722                                  those are 3 words   \n2999        2999  953721                                   round trip time?   \n\n     classification     score  \n0         not_toxic  0.001290  \n1         not_toxic  0.001271  \n2         not_toxic  0.001034  \n3             toxic  0.899223  \n4         not_toxic  0.000989  \n...             ...       ...  \n2995      not_toxic  0.001582  \n2996      not_toxic  0.082593  \n2997      not_toxic  0.003915  \n2998      not_toxic  0.004281  \n2999      not_toxic  0.001208  \n\n[3000 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>message</th>\n      <th>classification</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>957048</td>\n      <td>So considering battery degradation age and cycles</td>\n      <td>not_toxic</td>\n      <td>0.001290</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>957047</td>\n      <td>so yeah it had its fair life at this point</td>\n      <td>not_toxic</td>\n      <td>0.001271</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>957046</td>\n      <td>it’s an Oct 2020 unit, used since Dec 2020 by ...</td>\n      <td>not_toxic</td>\n      <td>0.001034</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>957045</td>\n      <td>I do hope it goes service instantly cause aasp...</td>\n      <td>toxic</td>\n      <td>0.899223</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>957044</td>\n      <td>When you actually put that into perspective yo...</td>\n      <td>not_toxic</td>\n      <td>0.000989</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2995</th>\n      <td>2995</td>\n      <td>953725</td>\n      <td>need to get ready for work</td>\n      <td>not_toxic</td>\n      <td>0.001582</td>\n    </tr>\n    <tr>\n      <th>2996</th>\n      <td>2996</td>\n      <td>953724</td>\n      <td>gm</td>\n      <td>not_toxic</td>\n      <td>0.082593</td>\n    </tr>\n    <tr>\n      <th>2997</th>\n      <td>2997</td>\n      <td>953723</td>\n      <td>i can confirm</td>\n      <td>not_toxic</td>\n      <td>0.003915</td>\n    </tr>\n    <tr>\n      <th>2998</th>\n      <td>2998</td>\n      <td>953722</td>\n      <td>those are 3 words</td>\n      <td>not_toxic</td>\n      <td>0.004281</td>\n    </tr>\n    <tr>\n      <th>2999</th>\n      <td>2999</td>\n      <td>953721</td>\n      <td>round trip time?</td>\n      <td>not_toxic</td>\n      <td>0.001208</td>\n    </tr>\n  </tbody>\n</table>\n<p>3000 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import prettyprinter as pp \n",
    "\n",
    "# Import the dataset (in this case, Basic Moderation, Group A)\n",
    "df = pd.read_csv('/Users/george/Desktop/Uni/2023-2024/Thesis/Final Thesis Collection/testCSV/testwithtoxicity.csv')\n",
    "\n",
    "# # Output total number of rows (messages) \n",
    "# print(\"Total number of messages: \", len(df))\n",
    "# # Output the percentage of messages that contain 'toxic' in the classification column\n",
    "# print(\"Percentage of toxic messages: \", len(df[df['classification'] == 'toxic']) / len(df) * 100)\n",
    "# # Output the percentage of messages that contain 'non-toxic' in the classification column\n",
    "# print(\"Percentage of non-toxic messages: \", len(df[df['classification'] == 'not_toxic']) / len(df) * 100)\n",
    "# # Calculate the 85th percentile for the scores of toxic and non-toxic messages\n",
    "# toxic_threshold = df[df['classification'] == 'toxic']['score'].quantile(0.95)\n",
    "# non_toxic_threshold = df[df['classification'] == 'not_toxic']['score'].quantile(0.95)\n",
    "# \n",
    "# # Filter out the outliers\n",
    "# toxic_outliers = df[(df['classification'] == 'toxic') & (df['score'] > toxic_threshold)]\n",
    "# non_toxic_outliers = df[(df['classification'] == 'not_toxic') & (df['score'] > non_toxic_threshold)]\n",
    "# \n",
    "# # Print the toxic outliers df \n",
    "# toxic_outliers.head(10)\n",
    "# # Print the non-toxic outliers df\n",
    "# non_toxic_outliers.head(10)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T14:33:01.661201Z",
     "start_time": "2024-04-17T14:33:01.649308Z"
    }
   },
   "id": "a9e3d52edce134eb"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Save dataframe to csv\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Users/george/Desktop/Uni/2023-2024/Thesis/Final Thesis Collection/testCSV/testwithtoxicity.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Save dataframe to csv\n",
    "df.to_csv('/Users/george/Desktop/Uni/2023-2024/Thesis/Final Thesis Collection/testCSV/testwithtoxicity.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T13:14:42.984600Z",
     "start_time": "2024-05-10T13:14:42.638736Z"
    }
   },
   "id": "ebbc9d4ba54b9b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
