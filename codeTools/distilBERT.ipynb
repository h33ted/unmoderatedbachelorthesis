{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## DistilBERT Toxicity Classifier - Implementation - Modification to run on Apple Silicon\n",
    "\n",
    "George Cotea, 2024"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "774be2c8ed8115e0"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas\n",
    "import torch\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T12:56:19.454226Z",
     "start_time": "2024-04-08T12:56:19.450095Z"
    }
   },
   "id": "9e8e97ef4197d552"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n",
    "\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "model_name = \"citizenlab/distilbert-base-multilingual-cased-toxicity\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Setup MPS device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T13:26:02.301675Z",
     "start_time": "2024-05-10T13:25:57.828297Z"
    }
   },
   "id": "b1401070d6c62fee"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Import the CSV file with the messages to classify \n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/george/Desktop/Uni/2023-2024/Thesis/Final Thesis Collection/testCSV/nomoderationjoined.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T11:49:15.817879Z",
     "start_time": "2024-05-12T11:49:15.757345Z"
    }
   },
   "id": "e0e25c9afe58974f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Classifying messages:   0%|          | 0/50606 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca23fcf00d79472d9fe706ac62e04d9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjusted functions for manual inference\n",
    "def classify_text(text, tokenizer, model, device, threshold=2/3):\n",
    "    # Tokenization\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    input_ids = encoded_input['input_ids'].to(device)\n",
    "    attention_mask = encoded_input['attention_mask'].to(device)\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        predictions = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # Handling the output\n",
    "    predictions = predictions.cpu().numpy() # Move to CPU and transform to numpy array\n",
    "    toxic_scores = predictions[:, 0]  \n",
    "    \n",
    "    # Determine classification based on threshold\n",
    "    classification = 'toxic' if toxic_scores.mean() >= threshold else 'not_toxic'\n",
    "    score = toxic_scores.mean()\n",
    "    \n",
    "    return classification, score\n",
    "\n",
    "# Apply classification across DataFrame with progress bar\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(desc=\"Classifying messages\")\n",
    "\n",
    "# Ensure all messages are strings\n",
    "df['message'] = df['message'].astype(str)\n",
    "\n",
    "# Apply the classification function with progress_apply\n",
    "results = df['message'].progress_apply(lambda x: classify_text(x, tokenizer, model, device))\n",
    "df['classification'], df['score'] = zip(*results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T11:56:31.661594Z",
     "start_time": "2024-05-12T11:49:17.424180Z"
    }
   },
   "id": "206052d4b6d93e7d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/george/Desktop/Uni/2023-2024/Thesis/Final Thesis Collection/distilClassified/nomoderationjoinedtoxicity.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T11:56:33.670180Z",
     "start_time": "2024-05-12T11:56:33.534484Z"
    }
   },
   "id": "cbbf00c0cab19ffc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
