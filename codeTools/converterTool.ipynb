{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# converterTool\n",
    "### This is a tool that converts and reduces the scraped JSON from TGCollector for use with the DistilBERT model \n",
    "\n",
    " George Cotea, 2024"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae6f9ecc7e0c4bb1"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "467d65587f31e846"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T12:53:51.759982Z",
     "start_time": "2024-05-10T12:53:50.659262Z"
    }
   },
   "id": "5afe1249d9f90e3a"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    " path = '/Users/george/Desktop/Uni/2023-2024/Thesis/Final Thesis Collection/scrapedJSON'\n",
    "#Change this to the path of the folder containing the JSON files \n",
    "csv_path = '/Users/george/Desktop/Uni/2023-2024/Thesis/Final Thesis Collection/testCSV'\n",
    "#Change this to the path of the folder where you want the CSV files to be saved\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(path, filename)) as f:\n",
    "            data = json.load(f)\n",
    "            df = pd.DataFrame(data)\n",
    "            df = df[[\"id\", \"message\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T11:41:13.465825Z",
     "start_time": "2024-05-12T11:41:13.070846Z"
    }
   },
   "id": "9c96fec8d5390b93"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Importing regex for text preprocessing\n",
    "import re\n",
    "# Regex patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                           u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                           u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                           u\"\\U000024C2-\\U0001F251\" \n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "link_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "\n",
    "# Function to check if a string contains only emojis or links\n",
    "def contains_only_emojis_or_links(text):\n",
    "    cleaned_text = emoji_pattern.sub(r'', text)  # Remove emojis\n",
    "    cleaned_text = link_pattern.sub(r'', cleaned_text)  # Remove links\n",
    "    return not cleaned_text.strip()\n",
    "\n",
    "# Function to remove emojis and links from a string\n",
    "def remove_emojis_and_links(text):\n",
    "    text = emoji_pattern.sub(r'', text)  # Remove emojis\n",
    "    text = link_pattern.sub(r'', text)  # Remove links\n",
    "    return text\n",
    "\n",
    "# Remove rows that contain only emojis or links\n",
    "df['remove'] = df['message'].apply(contains_only_emojis_or_links)\n",
    "df = df[~df['remove']]\n",
    "\n",
    "# Clean messages to remove emojis and links\n",
    "df['message'] = df['message'].apply(remove_emojis_and_links)\n",
    "\n",
    "# Drop the auxiliary 'remove' column\n",
    "df.drop(columns=['remove'], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T11:41:14.924027Z",
     "start_time": "2024-05-12T11:41:14.862164Z"
    }
   },
   "id": "484fa34d2d51a902"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Save df to a csv file\n",
    "df.to_csv(os.path.join(csv_path, filename[:-5] + \".replace\"), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T11:41:17.134882Z",
     "start_time": "2024-05-12T11:41:17.083280Z"
    }
   },
   "id": "86aba866b0779f4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
